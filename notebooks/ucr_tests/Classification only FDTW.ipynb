{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from func_timeout import FunctionTimedOut, func_timeout\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !(find ../UCRArchive_2018/ -maxdepth 2 -type f -name \"*TRAIN.tsv\" -exec ls -al {} \\; | sort -k 5 -n | sed 's/ \\+/\\t/g' | cut -f 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FileNames:\n",
    "\n",
    "    name: str\n",
    "\n",
    "    train_file: str\n",
    "    test_file: str\n",
    "\n",
    "    train_dtw: str\n",
    "    train_fastdtw: str\n",
    "\n",
    "    test_dtw: str\n",
    "    test_fastdtw: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_files = []\n",
    "\n",
    "for file_name in tqdm(files):\n",
    "    name = file_name.split(\"/\")[-1].replace(\"_TRAIN.tsv\", \"\")\n",
    "    test_file = file_name.replace(\"TRAIN.tsv\", \"TEST.tsv\")\n",
    "\n",
    "    train_dtw = file_name.replace(\".tsv\", \"_train_dtw.csv\")\n",
    "    train_fastdtw = file_name.replace(\".tsv\", \"_train_fastdtw.csv\")\n",
    "\n",
    "    test_dtw = test_file.replace(\".tsv\", \"_train_dtw.csv\")\n",
    "    test_fastdtw = test_file.replace(\".tsv\", \"_train_fastdtw.csv\")\n",
    "\n",
    "    if not all(\n",
    "        [\n",
    "            os.path.exists(x)\n",
    "            for x in (\n",
    "                train_dtw,\n",
    "                train_fastdtw,\n",
    "                test_dtw,\n",
    "                test_fastdtw,\n",
    "            )\n",
    "        ]\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    fl = FileNames(\n",
    "        name=name,\n",
    "        train_file=file_name,\n",
    "        test_file=test_file,\n",
    "        train_dtw=train_dtw,\n",
    "        train_fastdtw=train_fastdtw,\n",
    "        test_dtw=test_dtw,\n",
    "        test_fastdtw=test_fastdtw,\n",
    "    )\n",
    "\n",
    "    frame = pd.read_csv(file_name, delimiter=\"\\t\", header=None)\n",
    "    test_frame = pd.read_csv(test_file, delimiter=\"\\t\", header=None)\n",
    "    sort_files.append([frame.shape[0] + test_frame.shape[0], frame.shape[1], fl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sort_files = sorted(sort_files, key=lambda x: x[0])\n",
    "sort_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.base import RegressorMixin, TransformerMixin\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import check_array, check_random_state\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def fastdtw_distance(x: Any, y: Any) -> float:\n",
    "    return fastdtw(x, y)[0]\n",
    "\n",
    "\n",
    "def euclidian_distance(x: Any, y: Any) -> float:\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "\n",
    "# Implementation of FDTW using Linear Regression for\n",
    "# new prototype selection\n",
    "class FeatureDTWTransformer(TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_start: int = 30,\n",
    "        n_add: int = 10,\n",
    "        n_max: int = 100,\n",
    "        by: str = \"mean\",\n",
    "        p_max: float = 0.7,\n",
    "        regressor: RegressorMixin = GradientBoostingRegressor,\n",
    "        copy_prototypes: bool = True,\n",
    "        distance_func: Callable[[Any, Any], float] = fastdtw_distance,\n",
    "        random_state: Optional[int] = None,\n",
    "        n_jobs: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        self.n_start = n_start\n",
    "        self.n_add = n_add\n",
    "        self.n_max = n_max\n",
    "        self.random_state = random_state\n",
    "        self.copy_prototypes = copy_prototypes\n",
    "        self.distance_func = distance_func\n",
    "        self.regressor = regressor\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self.by = by\n",
    "        self.p_max = p_max\n",
    "\n",
    "    def fit_step(self, X: Any, y: Any = None) -> bool:\n",
    "\n",
    "        if self.index_.shape[0] >= self.n_max:\n",
    "            return False\n",
    "\n",
    "        X_ = self.distances_\n",
    "\n",
    "        p_all = []\n",
    "\n",
    "        regressor = self.regressor(random_state=42)\n",
    "\n",
    "        for i, prototype in enumerate(self.prototypes_):\n",
    "\n",
    "            regressor.fit(X_[self.index_][:, i].reshape(-1, 1), self.s_corr_[i])\n",
    "\n",
    "            predicted = regressor.predict(X_[:, i].reshape(-1, 1))\n",
    "\n",
    "            predicted[predicted > 1] = 1\n",
    "            predicted[predicted < -1] = -1\n",
    "\n",
    "            predicted[self.index_] = self.s_corr_[i]\n",
    "\n",
    "            p_all.append(predicted)\n",
    "\n",
    "        p_all = np.abs(p_all)\n",
    "\n",
    "        p_mean = p_all.mean(axis=0)\n",
    "        p_max = p_all.max(axis=0)\n",
    "\n",
    "        condition = (p_mean < 0.5) & (p_max < self.p_max)\n",
    "\n",
    "        if self.by == \"mean\":\n",
    "            sort_by = p_mean.argsort()\n",
    "        else:\n",
    "            sort_by = p_max.argsort()\n",
    "\n",
    "        new_r = sort_by[condition[sort_by]][: self.n_add]\n",
    "\n",
    "        if new_r.shape[0] == 0:\n",
    "            return False\n",
    "\n",
    "        self.add_protype(new_r, X)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def fit(self, X: Any, y: Any = None) -> \"FeatureDTWTransformer\":\n",
    "\n",
    "        raw_data = self.__check_array(X)\n",
    "\n",
    "        self.fin = False\n",
    "        self._shape = raw_data.shape\n",
    "\n",
    "        rnd = check_random_state(self.random_state)\n",
    "\n",
    "        self.index_ = rnd.choice(self._shape[0], self.n_start, replace=False)\n",
    "\n",
    "        self.prototypes_ = np.array(raw_data[self.index_], copy=self.copy_prototypes)\n",
    "\n",
    "        self.transform(X)\n",
    "\n",
    "        while self.fit_step(X, y):\n",
    "            pass\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: Any, y: Any = None) -> np.ndarray:\n",
    "        raw_data = self.__check_array(X)\n",
    "\n",
    "        self.distances_ = raw_data[:, self.index_]\n",
    "\n",
    "        self.s_corr_ = spearmanr(self.distances_, axis=0)[0]\n",
    "\n",
    "        return self.distances_\n",
    "\n",
    "    def add_protype(self, index: Union[int, List[int]], X: Any) -> np.ndarray:\n",
    "\n",
    "        if isinstance(index, int):\n",
    "            index = [index]\n",
    "\n",
    "        mask = ~np.isin(index, self.index_)\n",
    "\n",
    "        new_index = np.array(index)[mask]\n",
    "\n",
    "        raw_data = self.__check_array(X)\n",
    "\n",
    "        new_prototypes = raw_data[new_index]\n",
    "\n",
    "        self.distances_ = np.hstack(\n",
    "            (\n",
    "                self.distances_,\n",
    "                raw_data[:, new_index],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.prototypes_ = np.vstack((self.prototypes_, new_prototypes))\n",
    "        self.index_ = np.append(self.index_, new_index)\n",
    "        self.s_corr_ = spearmanr(self.distances_, axis=0)[0]\n",
    "\n",
    "        return self.distances_\n",
    "\n",
    "    def remove_prototype(self, index: Union[int, List[int]]) -> np.ndarray:\n",
    "        if isinstance(index, int):\n",
    "            index = [index]\n",
    "\n",
    "        mask = ~np.isin(self.index_, index)\n",
    "\n",
    "        self.index_ = self.index_[mask]\n",
    "        self.prototypes_ = self.prototypes_[mask]\n",
    "        self.distances_ = self.distances_[:, mask]\n",
    "\n",
    "        return self.distances_\n",
    "\n",
    "    def __check_array(self, X: Any) -> np.ndarray:\n",
    "        return check_array(\n",
    "            X, accept_sparse=False, dtype=\"numeric\", force_all_finite=\"allow-nan\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "with open(f\"../logs/classification-{datetime.now().isoformat()}.csv\", \"w\") as out_file:\n",
    "    writer = csv.writer(out_file, delimiter=\",\")\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"n_features\",\n",
    "            \"n_max\",\n",
    "            \"1NN_fastdtw\",\n",
    "            \"features_fastdtw\",\n",
    "            \"fdtw_linear_fastdtw\",\n",
    "            \"n_linear_used\",\n",
    "        ]\n",
    "    )\n",
    "    for n_samples, n_len, file_name in tqdm(sort_files):\n",
    "\n",
    "        name = file_name.name\n",
    "\n",
    "        train_frame = pd.read_csv(file_name.train_file, delimiter=\"\\t\", header=None)\n",
    "        test_frame = pd.read_csv(file_name.test_file, delimiter=\"\\t\", header=None)\n",
    "\n",
    "        y_train = train_frame[0].values\n",
    "        y_test = test_frame[0].values\n",
    "\n",
    "        train_fastdtw = pd.read_csv(file_name.train_fastdtw, delimiter=\",\", header=None)\n",
    "        test_fastdtw = pd.read_csv(file_name.test_fastdtw, delimiter=\",\", header=None)\n",
    "\n",
    "        n_max = np.min([np.rint(0.5 * train_fastdtw.shape[0]).astype(int), 100])\n",
    "        row = [name, n_samples, n_max]\n",
    "\n",
    "        row.append(\n",
    "            round(\n",
    "                accuracy_score(\n",
    "                    y_pred=y_train[np.argmin(test_fastdtw.values, axis=1)],\n",
    "                    y_true=y_test,\n",
    "                ),\n",
    "                3,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Features DTW\n",
    "        try:\n",
    "            X_train = train_fastdtw.values\n",
    "            X_test = test_fastdtw.values\n",
    "\n",
    "            svc = LinearSVC(random_state=42, max_iter=1000)\n",
    "            func_timeout(600, svc.fit, args=(X_train, y_train))\n",
    "            predicted = func_timeout(600, svc.predict, args=(X_test,))\n",
    "\n",
    "            row.append(round(accuracy_score(y_true=y_test, y_pred=predicted), 3))\n",
    "        except FunctionTimedOut:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            arr = []\n",
    "            n_used = []\n",
    "\n",
    "            for i in range(3):\n",
    "                n_start = np.max([np.rint(0.2 * X_train.shape[0]).astype(int), 10])\n",
    "                n_add = n_start\n",
    "\n",
    "                fdtw = FeatureDTWTransformer(\n",
    "                    n_start=n_start, n_add=n_add, n_max=n_max, by=\"mean\", p_max=0.7\n",
    "                )\n",
    "\n",
    "                X_train = train_fastdtw.values\n",
    "\n",
    "                fdtw.fit(X_train)\n",
    "\n",
    "                X_train = X_train[:, fdtw.index_]\n",
    "\n",
    "                X_test = test_fastdtw.values[:, fdtw.index_]\n",
    "\n",
    "                svc = LinearSVC(random_state=42, max_iter=1000)\n",
    "                func_timeout(600, svc.fit, args=(X_train, y_train))\n",
    "                predicted = func_timeout(600, svc.predict, args=(X_test,))\n",
    "\n",
    "                arr.append(accuracy_score(y_true=y_test, y_pred=predicted))\n",
    "                n_used.append(fdtw.index_.shape[0])\n",
    "\n",
    "            row.append(round(np.mean(arr), 3))\n",
    "            row.append(round(np.mean(n_used), 3))\n",
    "        except FunctionTimedOut:\n",
    "            continue\n",
    "\n",
    "        writer.writerow(row)\n",
    "        out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Master's Thesis",
   "language": "python",
   "name": "masters-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
