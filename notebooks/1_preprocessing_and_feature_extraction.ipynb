{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Extraction\n",
    "\n",
    "In this notebook, we are applying preprocessing steps and extracting features from our dataset. \n",
    "\n",
    "Firstly, we remove outlying points using the first derivation of the power consumption curve (data points with significant sudden change). Then we use the Prophet by Facebook [[1]] to extract seasonalities and trends from our data.\n",
    "\n",
    "\n",
    "[1]: https://facebook.github.io/prophet/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.models import PyStanBackend\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PATH = Path(\"../electric_grid_data/\")\n",
    "SAVE_PATH = Path(\"../power_consumption_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pandas indices for our time series\n",
    "def create_weekly_index(seasson, header):\n",
    "    tmp = pd.Series(seasson, index=header).resample(\"7d\").sum()\n",
    "\n",
    "    start_seasson = tmp[tmp == 24 * 7].index[0]\n",
    "\n",
    "    return pd.date_range(start=start_seasson, freq=\"1h\", periods=24 * 7)\n",
    "\n",
    "\n",
    "def create_daily_index(day, header):\n",
    "    tmp = pd.Series(day, index=header).resample(\"1d\").sum()\n",
    "\n",
    "    start_day = tmp[tmp == 24].index[0]\n",
    "\n",
    "    return pd.date_range(start=start_day, freq=\"1h\", periods=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The older version of the Prophet did not allow\n",
    "# skipping Newton optimization, which is slower and\n",
    "# takes too much time on our dataset.\n",
    "# This workaround should not be necessary once\n",
    "# you're using newer versions of Prophet.\n",
    "class BackendWithoutNewton(PyStanBackend):\n",
    "    def fit(self, stan_init, stan_data, **kwargs) -> dict:\n",
    "\n",
    "        args = dict(\n",
    "            data=stan_data,\n",
    "            init=lambda: stan_init,\n",
    "            algorithm=\"Newton\" if stan_data[\"T\"] < 100 else \"LBFGS\",\n",
    "            iter=1e4,\n",
    "        )\n",
    "        args.update(kwargs)\n",
    "\n",
    "        # Remove Newton fallback\n",
    "        self.stan_fit = self.model.optimizing(**args)\n",
    "\n",
    "        params = dict()\n",
    "\n",
    "        for par in self.stan_fit.keys():\n",
    "            params[par] = self.stan_fit[par].reshape((1, -1))\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOAD_PATH.joinpath(\"data_grid.csv\"), newline=\"\") as input_file, open(\n",
    "    SAVE_PATH.joinpath(\"kwh_hours.csv\"), \"w\"\n",
    ") as kwh_hours_file, open(\n",
    "    SAVE_PATH.joinpath(\"work_day.csv\"), \"w\"\n",
    ") as work_day_file, open(\n",
    "    SAVE_PATH.joinpath(\"free_day.csv\"), \"w\"\n",
    ") as free_day_file, open(\n",
    "    SAVE_PATH.joinpath(\"spring_week.csv\"), \"w\"\n",
    ") as spring_week_file, open(\n",
    "    SAVE_PATH.joinpath(\"summer_week.csv\"), \"w\"\n",
    ") as summer_week_file, open(\n",
    "    SAVE_PATH.joinpath(\"autumn_week.csv\"), \"w\"\n",
    ") as autumn_week_file, open(\n",
    "    SAVE_PATH.joinpath(\"winter_week.csv\"), \"w\"\n",
    ") as winter_week_file, open(\n",
    "    SAVE_PATH.joinpath(\"trend.csv\"), \"w\"\n",
    ") as trend_file, open(\n",
    "    SAVE_PATH.joinpath(\"year.csv\"), \"w\"\n",
    ") as year_file, open(\n",
    "    SAVE_PATH.joinpath(\"residuals_hist.csv\"), \"w\"\n",
    ") as res_hist_file, open(\n",
    "    SAVE_PATH.joinpath(\"residuals_bin.csv\"), \"w\"\n",
    ") as res_bin_file:\n",
    "\n",
    "    reader = csv.reader(input_file, delimiter=\";\")\n",
    "    w_kwh_hours = csv.writer(kwh_hours_file, delimiter=\",\")\n",
    "\n",
    "    w_work_day = csv.writer(work_day_file, delimiter=\",\")\n",
    "    w_free_day = csv.writer(free_day_file, delimiter=\",\")\n",
    "\n",
    "    w_spring_week = csv.writer(spring_week_file, delimiter=\",\")\n",
    "    w_summer_week = csv.writer(summer_week_file, delimiter=\",\")\n",
    "    w_autumn_week = csv.writer(autumn_week_file, delimiter=\",\")\n",
    "    w_winter_week = csv.writer(winter_week_file, delimiter=\",\")\n",
    "\n",
    "    w_trend = csv.writer(trend_file, delimiter=\",\")\n",
    "    w_year = csv.writer(year_file, delimiter=\",\")\n",
    "\n",
    "    w_rhist = csv.writer(res_hist_file, delimiter=\",\")\n",
    "    w_rbin = csv.writer(res_bin_file, delimiter=\",\")\n",
    "\n",
    "    for index, line in enumerate(tqdm(reader)):\n",
    "        if index == 0:\n",
    "            # Header row with dates\n",
    "            header = pd.to_datetime(line[4:])\n",
    "\n",
    "            s_header = (\n",
    "                pd.Series(np.ones(len(header)), index=header).resample(\"1h\").mean()\n",
    "            )\n",
    "            s_header = s_header[~np.isnan(s_header)]\n",
    "            s_index = s_header.index\n",
    "\n",
    "            dates_frame = pd.DataFrame(index=s_index)\n",
    "            dates_frame[\"ds\"] = s_index\n",
    "            dates_frame[\"y\"] = np.nan\n",
    "\n",
    "            dates_frame[\"spring\"] = np.isin(s_index.month, [3, 4, 5])\n",
    "            dates_frame[\"summer\"] = np.isin(s_index.month, [6, 7, 8])\n",
    "            dates_frame[\"autumn\"] = np.isin(s_index.month, [9, 10, 11])\n",
    "            dates_frame[\"winter\"] = np.isin(s_index.month, [12, 1, 2])\n",
    "\n",
    "            # initializing holydays\n",
    "            sk_h = holidays.Slovakia()\n",
    "\n",
    "            dates_frame[\"free_day\"] = np.array([x in sk_h for x in s_index]) | np.isin(\n",
    "                s_index.day_name(), [\"Saturday\", \"Sunday\"]\n",
    "            )\n",
    "            dates_frame[\"work_day\"] = ~dates_frame[\"free_day\"]\n",
    "\n",
    "            spring_index = create_weekly_index(dates_frame[\"spring\"], s_index)\n",
    "            summer_index = create_weekly_index(dates_frame[\"summer\"], s_index)\n",
    "            autumn_index = create_weekly_index(dates_frame[\"autumn\"], s_index)\n",
    "            winter_index = create_weekly_index(dates_frame[\"winter\"], s_index)\n",
    "\n",
    "            free_day_index = create_daily_index(dates_frame[\"free_day\"], s_index)\n",
    "            work_day_index = create_daily_index(dates_frame[\"work_day\"], s_index)\n",
    "\n",
    "            w_kwh_hours.writerow(s_index)\n",
    "\n",
    "            continue\n",
    "\n",
    "        if line[2].lower() != \"p+\":\n",
    "            continue\n",
    "\n",
    "        # Prepare data\n",
    "        try:\n",
    "            data = np.array(line[4:])\n",
    "            data[data == \"\"] = np.nan  # setting empty cells to nan\n",
    "            data = data.astype(float)\n",
    "            data[data < 0] = np.nan  # removing values bellow zero\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        data = pd.Series(data, index=header).resample(\"15min\").mean()\n",
    "\n",
    "        # Removing anomalous points by using the first derivation\n",
    "        # of the power consumption curve\n",
    "        s_diff = data.diff().diff()\n",
    "\n",
    "        q_low = np.nanquantile(s_diff, 0.005)\n",
    "        q_high = np.nanquantile(s_diff, 0.995)\n",
    "\n",
    "        data = data[(s_diff > q_low) & (s_diff < q_high)]\n",
    "\n",
    "        data = data.resample(\"1h\").mean() * 4\n",
    "        data = data[~np.isnan(data)]\n",
    "\n",
    "        # Remove data with a lot of nans\n",
    "        if data.shape[0] / s_index.shape[0] < 0.5:\n",
    "            continue\n",
    "\n",
    "        # Prepare data for Prophet\n",
    "\n",
    "        dates_frame.loc[data.index, \"y\"] = np.log1p(data)\n",
    "\n",
    "        # Setup Prophet\n",
    "        # Prophet definition\n",
    "        m = Prophet(\n",
    "            n_changepoints=0,\n",
    "            growth=\"linear\",\n",
    "            seasonality_mode=\"additive\",\n",
    "            yearly_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "        )\n",
    "        m.stan_backend = BackendWithoutNewton()\n",
    "\n",
    "        # Setting-up seassonalities and holidays in Slovakia\n",
    "        m.add_country_holidays(country_name=\"SK\")\n",
    "\n",
    "        m.add_seasonality(name=\"yearly\", period=365, fourier_order=20)\n",
    "        m.add_seasonality(\n",
    "            name=\"weekly_spring\", period=7, fourier_order=5, condition_name=\"spring\"\n",
    "        )\n",
    "        m.add_seasonality(\n",
    "            name=\"weekly_summer\", period=7, fourier_order=5, condition_name=\"summer\"\n",
    "        )\n",
    "        m.add_seasonality(\n",
    "            name=\"weekly_autumn\", period=7, fourier_order=5, condition_name=\"autumn\"\n",
    "        )\n",
    "        m.add_seasonality(\n",
    "            name=\"weekly_winter\", period=7, fourier_order=5, condition_name=\"winter\"\n",
    "        )\n",
    "\n",
    "        m.add_seasonality(\n",
    "            name=\"work_day\", period=1, fourier_order=3, condition_name=\"work_day\"\n",
    "        )\n",
    "        m.add_seasonality(\n",
    "            name=\"free_day\", period=1, fourier_order=3, condition_name=\"free_day\"\n",
    "        )\n",
    "\n",
    "        # Fit & predict Prophet\n",
    "        try:\n",
    "            m.fit(dates_frame)\n",
    "            forecast = m.predict(dates_frame)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        df = pd.merge(dates_frame[[\"ds\", \"y\"]], forecast, on=\"ds\")\n",
    "        df.set_index(\"ds\", inplace=True)\n",
    "\n",
    "        free_day_data = df[\"free_day\"].loc[free_day_index]\n",
    "        work_day_data = df[\"work_day\"].loc[work_day_index]\n",
    "\n",
    "        spring_data = df[\"weekly_spring\"].loc[spring_index].resample(\"2h\").mean()\n",
    "        summer_data = df[\"weekly_summer\"].loc[summer_index].resample(\"2h\").mean()\n",
    "        autumn_data = df[\"weekly_autumn\"].loc[autumn_index].resample(\"2h\").mean()\n",
    "        winter_data = df[\"weekly_winter\"].loc[winter_index].resample(\"2h\").mean()\n",
    "\n",
    "        trend_data = df[\"trend\"].resample(\"w\").mean().interpolate()\n",
    "        year_data = df[\"yearly\"].resample(\"3d\").mean().interpolate()\n",
    "\n",
    "        residuals = df[\"yhat\"] - df[\"y\"]\n",
    "        hist, bin_edges = np.histogram(residuals, \"auto\", density=True)\n",
    "\n",
    "        # Write data\n",
    "        w_kwh_hours.writerow(np.expm1(df[\"y\"]).round(3))\n",
    "\n",
    "        w_free_day.writerow(free_day_data)\n",
    "        w_work_day.writerow(work_day_data)\n",
    "\n",
    "        w_spring_week.writerow(spring_data)\n",
    "        w_summer_week.writerow(summer_data)\n",
    "        w_autumn_week.writerow(autumn_data)\n",
    "        w_winter_week.writerow(winter_data)\n",
    "\n",
    "        w_trend.writerow(trend_data)\n",
    "        w_year.writerow(year_data)\n",
    "\n",
    "        w_rhist.writerow(hist)\n",
    "        w_rbin.writerow(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Master's Thesis",
   "language": "python",
   "name": "masters-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
